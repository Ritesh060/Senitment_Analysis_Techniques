{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c302feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "059aa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews = pd.read_csv(\"imdb_reviews.csv\")\n",
    "test_reviews = pd.read_csv(\"test_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c52c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;START this film was just brilliant casting lo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;START big hair big boobs bad music and a gian...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;START this has to be one of the worst films o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;START the &lt;UNK&gt; &lt;UNK&gt; at storytelling the tra...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;START worst mistake of my life br br i picked...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews Sentiment\n",
       "0  <START this film was just brilliant casting lo...  positive\n",
       "1  <START big hair big boobs bad music and a gian...  negative\n",
       "2  <START this has to be one of the worst films o...  negative\n",
       "3  <START the <UNK> <UNK> at storytelling the tra...  positive\n",
       "4  <START worst mistake of my life br br i picked...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4798df83",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = pd.read_csv(\"word_indexes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "449ca87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tsukino</td>\n",
       "      <td>52009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nunnery</td>\n",
       "      <td>52010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sonja</td>\n",
       "      <td>16819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vani</td>\n",
       "      <td>63954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woods</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spiders</td>\n",
       "      <td>16118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hanging</td>\n",
       "      <td>2348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>woody</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trawling</td>\n",
       "      <td>52011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hold's</td>\n",
       "      <td>52012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>comically</td>\n",
       "      <td>11310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>localized</td>\n",
       "      <td>40833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>disobeying</td>\n",
       "      <td>30571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>'royale</td>\n",
       "      <td>52013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>harpo's</td>\n",
       "      <td>40834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>canet</td>\n",
       "      <td>52014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aileen</td>\n",
       "      <td>19316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>acurately</td>\n",
       "      <td>52015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>diplomat's</td>\n",
       "      <td>52016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rickman</td>\n",
       "      <td>25245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Words  Indexes\n",
       "0      tsukino    52009\n",
       "1      nunnery    52010\n",
       "2        sonja    16819\n",
       "3         vani    63954\n",
       "4        woods     1411\n",
       "5      spiders    16118\n",
       "6      hanging     2348\n",
       "7        woody     2292\n",
       "8     trawling    52011\n",
       "9       hold's    52012\n",
       "10   comically    11310\n",
       "11   localized    40833\n",
       "12  disobeying    30571\n",
       "13     'royale    52013\n",
       "14     harpo's    40834\n",
       "15       canet    52014\n",
       "16      aileen    19316\n",
       "17   acurately    52015\n",
       "18  diplomat's    52016\n",
       "19     rickman    25245"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index.head(n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6418017",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict(zip(word_index.Words, word_indexes.Indexes)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55b3256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START\"] = 1\n",
    "word_index[\"UNK\"] = 2\n",
    "word_index[\"UNUSED\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23f2b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_encoder(text):\n",
    "    arr = [word_index[word] for word in text]\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "920cb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = imdb_reviews['Reviews'], imdb_reviews['Sentiment']\n",
    "test_data, test_labels = test_reviews['Reviews'], test_reviews['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6637612",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.apply(lambda review : review.split())\n",
    "test_data = test_data.apply(lambda review : review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d44ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.apply(review_encoder)\n",
    "test_data = test_data.apply(review_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9e5355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentiments(sentiment):\n",
    "    if sentiment == 'postive':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "train_labels = train_labels.apply(encode_sentiments)\n",
    "test_labels = test_labels.apply(encode_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce49da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value = word_index[\"<PAD>\"], padding = 'post', maxlen=500)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value = word_index[\"<PAD>\"], padding = 'post', maxlen = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "494004c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Embedding(10000, 16, input_length = 500),\n",
    "                        keras.layers.GlobalAveragePooling1D(),\n",
    "                        keras.layers.Dense(16, activation = 'relu'),\n",
    "                        keras.layers.Dense(1,activation = 'sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21a1b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ae47b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "49/49 [==============================] - 7s 92ms/step - loss: 0.6379 - accuracy: 0.9133 - val_loss: 0.5375 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.4088 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.1773 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.0663 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "49/49 [==============================] - 4s 74ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "49/49 [==============================] - 4s 73ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "49/49 [==============================] - 3s 67ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "49/49 [==============================] - 3s 65ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "49/49 [==============================] - 3s 67ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 9.7374e-04 - accuracy: 1.0000 - val_loss: 8.9002e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 8.3059e-04 - accuracy: 1.0000 - val_loss: 7.6315e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 7.1551e-04 - accuracy: 1.0000 - val_loss: 6.6043e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 6.2174e-04 - accuracy: 1.0000 - val_loss: 5.7618e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 5.4441e-04 - accuracy: 1.0000 - val_loss: 5.0631e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 4.7996e-04 - accuracy: 1.0000 - val_loss: 4.4779e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "49/49 [==============================] - 4s 76ms/step - loss: 4.2575e-04 - accuracy: 1.0000 - val_loss: 3.9835e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "49/49 [==============================] - 4s 75ms/step - loss: 3.7975e-04 - accuracy: 1.0000 - val_loss: 3.5621e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 3.4041e-04 - accuracy: 1.0000 - val_loss: 3.2006e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "49/49 [==============================] - 3s 69ms/step - loss: 3.0654e-04 - accuracy: 1.0000 - val_loss: 2.8882e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "49/49 [==============================] - 3s 67ms/step - loss: 2.7718e-04 - accuracy: 1.0000 - val_loss: 2.6167e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "49/49 [==============================] - 3s 66ms/step - loss: 2.5159e-04 - accuracy: 1.0000 - val_loss: 2.3793e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "49/49 [==============================] - 3s 68ms/step - loss: 2.2917e-04 - accuracy: 1.0000 - val_loss: 2.1706e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "49/49 [==============================] - 4s 83ms/step - loss: 2.0941e-04 - accuracy: 1.0000 - val_loss: 1.9865e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "49/49 [==============================] - 3s 70ms/step - loss: 1.9193e-04 - accuracy: 1.0000 - val_loss: 1.8231e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_labels, epochs = 30, batch_size = 512, validation_data = (test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d63e002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 1.8231e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db108024",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "265f0a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews      <START eric ability to roll from character to ...\n",
      "Sentiment                                             positive\n",
      "Name: 23, dtype: object\n"
     ]
    }
   ],
   "source": [
    "user_review = test_reviews.loc[index]\n",
    "print(user_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d9c205e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 237ms/step\n",
      "Negative Sentiment\n"
     ]
    }
   ],
   "source": [
    "user_review = test_data[index]\n",
    "user_review = np.array([user_review])\n",
    "if(model.predict(user_review) > 0.5).astype(\"int32\"):\n",
    "    print(\"Postive Sentiment\")\n",
    "else:\n",
    "    print(\"Negative Sentiment\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
